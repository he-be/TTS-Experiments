/home/mh/dev/T5Gemma-TTS/failure_report_20251224.md
このレポートにあるように、片側だけ漫才をAI生成する試みは、いままでプロンプトを試行錯誤してきたものの失敗が続いている。
これから既存の試行錯誤を破棄し、根本的に異なるアプローチでやり直す。

# 新たなアプローチ
## 大方針
/home/mh/dev/T5Gemma-TTS/texts/1219_2.txt
この例を、完璧な片側だけ漫才のサンプルとする。
少しずつ漫才生成方法を改良し、このサンプルに寄せていくことを目標とする。これにより、根本的に異なるアプローチで、小さな改善サイクルを、人間のフィードバックで回し、最終的にこの特定のサンプルをほぼ再現できるところまで継続する。
キャラ設定ファイル、片側だけ漫才のプロンプトはあなたが初期値を考案する。
## ステップ
1. 完璧な片側だけ漫才のサンプルと、生成結果の差分の評価方法を整備する。また、生成結果Aと生成結果A’のAB評価の方法を、片側だけ漫才としての完成度や面白さの観点から評価する方法を整備する。これらは、LLM-as-a-Judgeの方法で、相違点を評価し、改善の方向性を考察する準備をする。
2. 現状のキャラ設定ファイルと、片側だけ漫才のプロンプトで生成結果Aを得る。
3. 生成結果Aと、完璧な片側だけ漫才のサンプルを比較して、LLM-as-a-Judgeで評価する。改善の方向性を考察する。
4. 現状のキャラ設定ファイルと、片側だけ漫才のプロンプトを小さく改良する。生成結果Bを得る。
5. 生成結果Bと、生成結果Aを比較して、LLM-as-a-Judgeで評価する。Aが優れている場合、4.の改良を破棄し、再度小さく改良する。Bが優れている場合、4.の改良を採用する。
6. 定期的に人間のフィードバックを得るために出力し、改善の方向性を人間に確認、入力させる。
## 実装
gradioとは関係のない、Pythonを書いて。
モデルは、　/home/mh/dev/T5Gemma-TTS/script_generator.py　とまったく同様にする。